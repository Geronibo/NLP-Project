{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2a7621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Counter\n",
      "  Downloading Counter-1.0.0.tar.gz (5.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: Counter\n",
      "  Building wheel for Counter (setup.py): started\n",
      "  Building wheel for Counter (setup.py): finished with status 'done'\n",
      "  Created wheel for Counter: filename=Counter-1.0.0-py3-none-any.whl size=5425 sha256=811ff1b42ac242dc91ca4893852f02302805a77f19aa57a1fb736d09e843a8c0\n",
      "  Stored in directory: c:\\users\\ibrah\\appdata\\local\\pip\\cache\\wheels\\08\\5b\\a0\\8f15503db6a45a1d8747bf0f1438411cb37484ac4dfdfe6c0b\n",
      "Successfully built Counter\n",
      "Installing collected packages: Counter\n",
      "Successfully installed Counter-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f47bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('obezite', 1735), ('bir', 1723), ('olarak', 1184), ('fazla', 878), ('olduğu', 851), ('göre', 763), ('olan', 746), ('ark', 746), ('şişmanlık', 727), ('bki', 591), ('arasında', 563), ('beslenme', 515), ('öğrencilerin', 510), ('yüksek', 492), ('yapılan', 469), ('çocuk', 452), ('fiziksel', 435), ('çocukların', 428), ('kilo', 425), ('hakkında', 419), ('p', 412), ('yağ', 407), ('önemli', 403), ('yaş', 401), ('tablo', 392)]\n"
     ]
    }
   ],
   "source": [
    "# ADIM 1\n",
    "from collections import Counter\n",
    "\n",
    "# Dosyayı okuma modunda aç\n",
    "with open('islenmisveri2.txt', 'r', encoding='utf-8') as dosya:\n",
    "    metin = dosya.read()  # Dosyanın tamamını oku\n",
    "\n",
    "# Metni kelimelere ayırma (tokenize)\n",
    "kelimeler = metin.split()  # Basit bir örnek olarak metni boşluklardan ayırarak kelimelere böldük\n",
    "\n",
    "# Kelimelerin geçiş sayılarını hesapla\n",
    "kelime_sayilari = Counter(kelimeler)\n",
    "\n",
    "# En fazla geçen 20 kelimeyi bul\n",
    "en_fazla_gecen_25 = kelime_sayilari.most_common(25)\n",
    "\n",
    "print(en_fazla_gecen_25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6348b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Word2Vec\n",
      "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
      "     ---------------------------------------- 0.0/42.3 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.3 kB 640.0 kB/s eta 0:00:01\n",
      "     --------------------------- ---------- 30.7/42.3 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/42.3 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.3/42.3 kB 294.3 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.2 in d:\\anaconda\\lib\\site-packages (from Word2Vec) (1.24.3)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from Word2Vec) (1.2.0)\n",
      "Building wheels for collected packages: Word2Vec\n",
      "  Building wheel for Word2Vec (pyproject.toml): started\n",
      "  Building wheel for Word2Vec (pyproject.toml): finished with status 'error'\n",
      "Failed to build Word2Vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for Word2Vec (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [129 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib\n",
      "  creating build\\lib\\word2vec\n",
      "  copying word2vec\\io.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\scripts_interface.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\utils.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\wordclusters.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\wordvectors.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\_generated_version.py -> build\\lib\\word2vec\n",
      "  copying word2vec\\__init__.py -> build\\lib\\word2vec\n",
      "  creating build\\lib\\word2vec\\tests\n",
      "  copying word2vec\\tests\\test_core.py -> build\\lib\\word2vec\\tests\n",
      "  copying word2vec\\tests\\test_import.py -> build\\lib\\word2vec\\tests\n",
      "  copying word2vec\\tests\\test_scripts_present.py -> build\\lib\\word2vec\\tests\n",
      "  copying word2vec\\tests\\__init__.py -> build\\lib\\word2vec\\tests\n",
      "  running egg_info\n",
      "  writing word2vec.egg-info\\PKG-INFO\n",
      "  writing dependency_links to word2vec.egg-info\\dependency_links.txt\n",
      "  writing requirements to word2vec.egg-info\\requires.txt\n",
      "  writing top-level names to word2vec.egg-info\\top_level.txt\n",
      "  reading manifest file 'word2vec.egg-info\\SOURCES.txt'\n",
      "  adding license file 'LICENSE.txt'\n",
      "  writing manifest file 'word2vec.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\ibrah\\AppData\\Local\\Temp\\pip-build-env-7j8l_0m8\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:207: _Warning: Package 'word2vec.includes' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'word2vec.includes' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'word2vec.includes' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'word2vec.includes' to be distributed and are\n",
      "          already explicitly excluding 'word2vec.includes' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  C:\\Users\\ibrah\\AppData\\Local\\Temp\\pip-build-env-7j8l_0m8\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:207: _Warning: Package 'word2vec.includes.win32' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'word2vec.includes.win32' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'word2vec.includes.win32' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'word2vec.includes.win32' to be distributed and are\n",
      "          already explicitly excluding 'word2vec.includes.win32' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  creating build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\Makefile -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\compute-accuracy.c -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\distance.c -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\word-analogy.c -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\word2phrase.c -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\word2vec-sentence2vec.c -> build\\lib\\word2vec\\includes\n",
      "  copying word2vec\\includes\\word2vec.c -> build\\lib\\word2vec\\includes\n",
      "  creating build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\Makefile -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\compute-accuracy.c -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\distance.c -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\win32-port.h -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\word-analogy.c -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\word2phrase.c -> build\\lib\\word2vec\\includes\\win32\n",
      "  copying word2vec\\includes\\win32\\word2vec.c -> build\\lib\\word2vec\\includes\\win32\n",
      "  installing to build\\bdist.win-amd64\\wheel\n",
      "  running install\n",
      "  Running custom Install command\n",
      "  Compiling: gcc C:\\Users\\ibrah\\AppData\\Local\\Temp\\pip-install-bvixgwke\\word2vec_225d44f6fc354001a7746460fe73576b\\word2vec\\includes\\win32/word2vec.c -o Scripts\\word2vec.exe -O2 -Wall -funroll-loops\n",
      "  error: [WinError 2] Sistem belirtilen dosyayı bulamıyor\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Word2Vec\n",
      "ERROR: Could not build wheels for Word2Vec, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac7fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec modeli başarıyla eğitildi ve kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# ADIM 2\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "\n",
    "dosya_yolu = 'islenmisveri2.txt'\n",
    "\n",
    "# metni okudum ve küçük harfe çevirerek liste oluşturdum\n",
    "if os.path.exists(dosya_yolu):\n",
    "    with open(dosya_yolu, 'r', encoding='utf-8') as dosya:\n",
    "        metin = dosya.read().lower()  # Metni okuttum ve küçük harfe çevirdim\n",
    "        \n",
    "    # Metni kelimelere ayırdım\n",
    "    kelime_listesi = metin.split()  \n",
    "    \n",
    "    # Word2Vec modelini eğittim\n",
    "    model = Word2Vec(sentences=[kelime_listesi], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    \n",
    "    # Eğitilmiş modeli kaydettim\n",
    "    model.save(\"egitilmis_word2vec_model\")\n",
    "    \n",
    "    print(\"Word2Vec modeli başarıyla eğitildi ve kaydedildi.\")\n",
    "else:\n",
    "    print(\"Dosya bulunamadı.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8b26f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obezite: ['gerekli', 'devlet', '1657', '5408', 'farmakoterapinin']\n",
      "bir: ['öğünlerin', 'yiyip', 'frekanslarda', '10257', 'kükürt']\n",
      "olarak: ['tarafından', 'yiğit', 'ilgisiz', '9084', '7725']\n"
     ]
    }
   ],
   "source": [
    "# ADIM 2\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "model = Word2Vec.load(\"egitilmis_word2vec_model\")  # Eğitilmiş modelin dosya yolu\n",
    "\n",
    "# Her kelimenin en benzer 5 kelimesini bul\n",
    "kelimeler = [\"obezite\", \"bir\", \"olarak\"]  # Analiz yapmak istediğiniz kelimeler\n",
    "benzer_kelimeler = {}\n",
    "\n",
    "for kelime in kelimeler:\n",
    "    benzer_kelimeler[kelime] = [kel for kel, _ in model.wv.most_similar(kelime, topn=5)]\n",
    "\n",
    "# Sadece kelimeleri içeren çıktıyı yazdır\n",
    "for kelime, benzerler in benzer_kelimeler.items():\n",
    "    print(f\"{kelime}: {benzerler}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0598dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText modeli başarıyla eğitildi ve kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# ADIM 2\n",
    "\n",
    "from gensim.models import FastText\n",
    "import os\n",
    "\n",
    "# Dosya yolu\n",
    "dosya_yolu = 'islenmisveri2.txt'\n",
    "\n",
    "# Eğer dosya varsa, metni oku ve küçük harfe çevirerek liste oluştur\n",
    "if os.path.exists(dosya_yolu):\n",
    "    with open(dosya_yolu, 'r', encoding='utf-8') as dosya:\n",
    "        metin = dosya.read().lower()  # Metni oku ve küçük harfe çevir\n",
    "        \n",
    "    # Metni cümlelere ayırma\n",
    "    cumle_listesi = metin.split('.')  # Varsayılan olarak cümleleri noktadan ayırır\n",
    "    \n",
    "    # FastText modelini eğit\n",
    "    model = FastText(sentences=cumle_listesi, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    \n",
    "    # Eğitilmiş modeli kaydet\n",
    "    model.save(\"egitilmis_fasttext_model\")\n",
    "    \n",
    "    print(\"FastText modeli başarıyla eğitildi ve kaydedildi.\")\n",
    "else:\n",
    "    print(\"Dosya bulunamadı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe365215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obezite: ['\\n', '\\t', '1', '6', '8']\n",
      "bir: ['6', '2', '1', '\\n', '8']\n",
      "olarak: ['x', '3', 'c', '0', 'w']\n"
     ]
    }
   ],
   "source": [
    "# ADIM 2\n",
    "\n",
    "from gensim.models import FastText\n",
    "\n",
    "# Önceden eğitilmiş bir FastText modelini yükleyin veya eğitin\n",
    "model = FastText.load(\"egitilmis_fasttext_model\")  # Eğitilmiş modelin dosya yolu\n",
    "\n",
    "# Her kelimenin en benzer 5 kelimesini bul\n",
    "kelimeler = [\"obezite\", \"bir\", \"olarak\"]  # Analiz yapmak istediğiniz kelimeler\n",
    "benzer_kelimeler = {}\n",
    "\n",
    "for kelime in kelimeler:\n",
    "    benzer_kelimeler[kelime] = [kel for kel, _ in model.wv.most_similar(kelime, topn=5)]\n",
    "\n",
    "# Sadece kelimeleri içeren çıktıyı yazdır\n",
    "for kelime, benzerler in benzer_kelimeler.items():\n",
    "    print(f\"{kelime}: {benzerler}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc418091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obezite: ['gerekli', 'devlet', '1657', '5408', 'farmakoterapinin']\n",
      "bir: ['öğünlerin', 'yiyip', 'frekanslarda', '10257', 'kükürt']\n",
      "olarak: ['tarafından', 'yiğit', 'ilgisiz', '9084', '7725']\n",
      "fazla: ['10406', '8691', 'yetersizliğinden', '2010', '10666']\n",
      "olduğu: ['salgıların', '10467', '8359', 'tutarlı', '1397']\n",
      "göre: ['onaylanacak', '9288', '11800', '5910', 'gençlerde']\n",
      "olan: ['çevrem', 'diğer', 'ayrımcı', 'bazılarıdır', '1101']\n",
      "ark: ['2117', 'kaybetmeye', '9184', '4433', 'besledikleri']\n",
      "şişmanlık: ['4629', '670', '3942', '8304', '868']\n",
      "arasında: ['gerekli', 'yapmamış', '2116', '5066', 'yaadığı']\n",
      "beslenme: ['1479', 'psikoloji', 'hassasiyeti', '8777', 'eğitimlerle']\n",
      "öğrencilerin: ['ayrılmaz', 'yoğunlaştığı', '1792', 'bozulmu', 'bradwisch']\n",
      "yüksek: ['tutulmaktadır', '556', '2756', '5259', '11246']\n",
      "yapılan: ['kalorilerde', 'cezar', '7422', 'ürünleridir', 'uyuma']\n",
      "çocuk: ['11902', 'yaklaşımları', 'negatif', '403', '10166']\n",
      "fiziksel: ['bilimini', 'sprey', '4096', '10705', 'dopamine']\n",
      "kilo: ['10032', '6696', 'bileşenleri', '8424', '6098']\n",
      "yağ: ['ilavesinden', '6051', '5350', 'depolarına', 'delikta']\n",
      "önemli: ['5879', 'değişir', 'vakalarına', '9035', '4357']\n",
      "yaş: ['depression', '11627', '1261', 'nios', '4681']\n"
     ]
    }
   ],
   "source": [
    "# ADIM 3\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"egitilmis_word2vec_model\") \n",
    "\n",
    "# Her kelimenin en benzer 5 kelimesini buldum\n",
    "kelimeler = [\"obezite\", \"bir\", \"olarak\", \"fazla\", \"olduğu\", \"göre\", \"olan\", \"ark\", \"şişmanlık\", \"arasında\", \"beslenme\", \"öğrencilerin\", \"yüksek\", \"yapılan\", \"çocuk\", \"fiziksel\", \"kilo\", \"yağ\", \"önemli\", \"yaş\"]  # Analiz yapmak istediğiniz kelimeler\n",
    "benzer_kelimeler = {}\n",
    "\n",
    "for kelime in kelimeler:\n",
    "    benzer_kelimeler[kelime] = [kel for kel, _ in model.wv.most_similar(kelime, topn=5)]\n",
    "\n",
    "# çıktı\n",
    "for kelime, benzerler in benzer_kelimeler.items():\n",
    "    print(f\"{kelime}: {benzerler}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a2ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec modeli başarıyla eğitildi ve kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# ADIM 4\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "dosya_yolu = 'islenmisveri2.txt'\n",
    "\n",
    "\n",
    "if os.path.exists(dosya_yolu):\n",
    "    with open(dosya_yolu, 'r', encoding='utf-8') as dosya:\n",
    "        metin = dosya.readlines()  # Metni oku\n",
    "    \n",
    "    # Metni cümlelere ayırma\n",
    "    cumle_listesi = [cumle.strip() for cumle in metin if cumle.strip()]  # Boş olmayan cümleleri al\n",
    "\n",
    "    # Her cümlenin token'larını oluşturma\n",
    "    token_cumleler = [word_tokenize(cumle.lower()) for cumle in cumle_listesi]\n",
    "\n",
    "    # TaggedDocument'ları oluştur(işaretlenmiş cümleleri)\n",
    "    tagged_cumleler = [TaggedDocument(words=cumle, tags=[str(i)]) for i, cumle in enumerate(token_cumleler)]\n",
    "\n",
    "    # modelin eğitimi\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "    model.build_vocab(tagged_cumleler)\n",
    "    model.train(tagged_cumleler, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    # modelin kaydedilmesi\n",
    "    model.save(\"egitilmis_doc2vec_model\")\n",
    "\n",
    "    print(\"Doc2Vec modeli başarıyla eğitildi ve kaydedildi.\")\n",
    "else:\n",
    "    print(\"Dosya bulunamadı.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe51a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. cümleye benzer cümleler:\n",
      "- 9812\n",
      "- 4588\n",
      "- 5846\n",
      "- 3508\n",
      "\n",
      "2. cümleye benzer cümleler:\n",
      "- 1754\n",
      "- 6728\n",
      "- 1759\n",
      "- 4882\n",
      "\n",
      "3. cümleye benzer cümleler:\n",
      "- 6800\n",
      "- 4799\n",
      "- 9127\n",
      "- 10895\n",
      "\n",
      "4. cümleye benzer cümleler:\n",
      "- 4499\n",
      "- 8205\n",
      "- 7087\n",
      "- 1781\n",
      "\n",
      "5. cümleye benzer cümleler:\n",
      "- 6276\n",
      "- 6\n",
      "- 1145\n",
      "- 1153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_9404\\96582936.py:12: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  benzer_cümleler = model.docvecs.most_similar([cümle_vektoru], topn=n)\n"
     ]
    }
   ],
   "source": [
    "# ADIM 5\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "model = Doc2Vec.load(\"egitilmis_doc2vec_model\")\n",
    "\n",
    "def benzer_cumleleri_bul(model, cümle, n=4):\n",
    "    token_cümle = word_tokenize(cümle.lower())\n",
    "    cümle_vektoru = model.infer_vector(token_cümle)\n",
    "    \n",
    "    benzer_cümleler = model.docvecs.most_similar([cümle_vektoru], topn=n)\n",
    "    \n",
    "    return [benzerlik[0] for benzerlik in benzer_cümleler]\n",
    "\n",
    "# Örnek 5 cümle\n",
    "örnek_cümleler = [\n",
    "    \"diyet ana ara öğünlerden oluşmalıdır büyük bir öğün yerine sık küçük öğünler tercih edilmelidir\",\n",
    "    \"mutlaka egzersizle beraber yapılmalıdır egzersiz programının kişiye göre düzenlenmesi gereklidir\",\n",
    "    \"ilkokul çağı çocuklarının sağlığı konusunda dikkat edilmesi gereken husus beslenme beslenme alışkanlığıdır çocukların beslenme alışkanlığı kazanmasında aile faktörü önemlidir et yumurta süt baklagil tahıl sebze meyve sağlıklı besinleri dengeli bir şekilde yemeyi çocuklara alışkanlık haline getirmek gerekmektedir\",\n",
    "    \"ancak obez çocukların çoğunda şişmanlığa olacak herhangi hormonal bozukluk saptanmaz\",\n",
    "    \"obezite vergileri çocuk obezitesinin önlenmesinde yardımcı bir uygulama olmaktan öteye gidememiştir durum obezite vergilerinin dezavantajları kapsamlı şekilde değerlendirildiğinde çocuk obezitesinin önlenmesinde vergiler yerine farklı politikaların tercih edilmesi gerektiği sonucuna varılmıştır obezite mücadelede kamu politikalarının etkinliğine ilişkin araştırmalar çocuk obezitesinin önlenmesinde fiziksel aktiviteyi arttırmaya yönelik girişimlerin beslenme dengesine yönelik girişimlere kıyasla etkili sonuçlar verdiğini göstermektedir\",\n",
    "]\n",
    "\n",
    "# Her bir cümle için benzer cümleleri bulma\n",
    "for idx, cümle in enumerate(örnek_cümleler, 1):\n",
    "    benzer_cümleler = benzer_cumleleri_bul(model, cümle)\n",
    "    print(f\"{idx}. cümleye benzer cümleler:\")\n",
    "    for benzer_cümle in benzer_cümleler:\n",
    "        print(\"-\", benzer_cümle)\n",
    "    print()\n",
    "    \n",
    "    # ÖNEMLİ! : Değerleri index olarak veriyor fakat raporlamada hepsine karşılık gelen değeri not defterine yazdım. Kontrol edebilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e49b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
